{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/display.py:689: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=http://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/?ex_cid=story-twitter width=700 height=550></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<iframe src=http://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/?ex_cid=story-twitter width=700 height=550></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference.\n",
    "\n",
    "**Descriptive statistics** describe a sample, **inferential statistics** infer predictions about a population.\n",
    "\n",
    "**Statistical inference** deals with understanding the quality of parameter estimates of a sample.\n",
    "\n",
    "Statistical inference produces **statistical propositions** about:\n",
    "\n",
    "+ point estimates (a particular value that best approximates some parameter of interest), \n",
    "+ confidence intervals (or set estimate) or \n",
    "+ the rejection of a hypothesis.\n",
    "\n",
    "Statistical inference is based on assumptions related to a statistical model or sampling process. Correct inference requires these assumptions to be correct.\n",
    "\n",
    "In this session we will develop the **frequentist inference paradigm**. It bases the production of propositions by considering repeated sampling of a population.**P-values and confidence intervals are its most common propositions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Variability in estimates.\n",
    "* 1.1 Point estimates\n",
    "* 1.2 Sample mean distribution\n",
    "* 1.3 Standard Error\n",
    "* 1.4 Bootstraping\n",
    "* 1.5 Confidence Intervals\n",
    "\n",
    "### 2 Hypothesis testing\n",
    "* 2.1. Confidence Interval tests\n",
    "* 2.2. P-values\n",
    "* 2.3. t-test\n",
    "* 2.4. Chi-squared test\n",
    "* 2.5. Wilcoxon signed-rank test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder\n",
    "\n",
    "After exploring the data and computing some descriptive statistics from the National Survey of Family Growth (NSFG) we have seen some **apparent effects** that seem to support a hypothesis: The mean pregnant lenght for first babies is larger than for other babies.\n",
    "\n",
    "But there are still **important** questions to be solved:\n",
    "\n",
    "+ What is the probability that **a result is caused by chance** (due to the particular sample)? \n",
    "+ Is it **statistically significant**?\n",
    "+ Is it **relevant**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('files/2002FemPreg.dat', 'r')\n",
    "\n",
    "def chr_int(a):\n",
    "    if a == '  ':\n",
    "        return 0\n",
    "    else:\n",
    "        return int(a)\n",
    "        \n",
    "preg=[]\n",
    "for line in file:\n",
    "    lst  = [int(line[:12]), int(line[274:276]), int(line[276]), \\\n",
    "                 chr_int(line[277:279]), float(line[422:440])]\n",
    "    preg.append(lst)\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(preg)\n",
    "df.columns = ['caseid', 'prglength', 'outcome', 'birthord', 'finalwgt']\n",
    "firstbirth = df[(df.outcome == 1) & (df.birthord == 1)]\n",
    "othersbirth = df[(df.outcome == 1) & (df.birthord >= 2)]\n",
    "\n",
    "# descriptive statistics\n",
    "muf = firstbirth['prglength'].mean()\n",
    "stdf = firstbirth['prglength'].std()\n",
    "\n",
    "print('First babies mean:',muf, 'STD:',stdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muo = othersbirth['prglength'].mean()\n",
    "stdo = othersbirth['prglength'].std()\n",
    "print('Other babies mean:', muo, 'STD:',stdo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variability in estimates.\n",
    "\n",
    "Descriptive statistics are not equal to the *truth* but they are better as more data become available. \n",
    "\n",
    "Moreover, they vary from one sample to another. It would be useful to know how variable they are from one sample to another!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Point estimates\n",
    "\n",
    "Let's suppose that we want to estimate the *population mean* based on the sample. \n",
    "\n",
    "The most intuitive\n",
    "way to go about doing this is to simply take the *sample mean*. The sample mean is a **point estimate of the population mean**. If we can only choose one value to estimate the population mean, this is our best guess.\n",
    "\n",
    "We can generate point estimates of other population parameters, such as the *population median* or *population standard deviation*.\n",
    "\n",
    "Estimates generally vary from one sample to another, and this sampling variation suggests our estimate may be close, but it will not be exactly equal to the parameter.\n",
    "We can see this by plotting a **running mean** from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "running_mean = np.array([0.0] * (len(firstbirth['prglength'])+1)) #array of zero's \n",
    "running_mean[0] = firstbirth['prglength'].values[0]\n",
    "\n",
    "i = 1\n",
    "for x in firstbirth['prglength']:\n",
    "    running_mean[i] = running_mean[i-1] + x\n",
    "    i += 1\n",
    "    \n",
    "running_mean = running_mean / np.array(range(1,len(firstbirth['prglength'])+2))\n",
    "mean = running_mean[len(firstbirth['prglength'])-1]\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(running_mean, lw=1.5, alpha=0.7)\n",
    "    plt.ylabel('Running mean')\n",
    "    plt.plot([0, len(firstbirth['prglength'])-1], [mean, mean], 'r-', lw=0.5, alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that even after 1000 samples, the mean can substantially vary. So, if we get several samples from a population we can build the *estimate distribution*. \n",
    "\n",
    "### 1.2. Sample mean distribution\n",
    "\n",
    "In our case, if we consider the full dataset a population, we can build the **empirical distribution of the sample mean** for a given number of observations (f.e. samples with 1000 observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = firstbirth['prglength']     # population\n",
    "\n",
    "N_test = 10000                   # number of different samples from the population\n",
    "elements = 1000                  # number of observations in each sample\n",
    "means = [0] * N_test             # samples' mean array\n",
    "\n",
    "for i in range(N_test):          # sample generation\n",
    "    rows = np.random.choice(df.index.values, elements)\n",
    "    sampled_df = df.loc[rows]\n",
    "    means[i]=sampled_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.hist(means,bins=30)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this empirical distribution to give sound answers to a series of interesting questions:\n",
    "\n",
    "+ What is the uncertainty of the sample mean?\n",
    "+ What is the probability of getting a sample mean $\\geq$ than $x$? Or in other words, is a given sample mean probable?\n",
    "+ Etc. \n",
    "\n",
    "That is, we can produce statistical propositions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"> The <b>sampling distribution</b> represents the distribution of a point estimate based on samples of a <b>fixed size</b> from a certain population. \n",
    "\n",
    "It is useful to think of a particular point estimate as being drawn from such a distribution. Understanding the concept of a sampling distribution is central to understanding statistical inference.\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Standard error of the mean\n",
    "\n",
    "If we do not have access to the population, the sampling distribution cannot be built empirically.\n",
    "\n",
    "It can be mathematically shown that given $n$ independent observations $\\{ x_i \\}_{i=1,..,n}$ from a population with a standard deviation $\\sigma_x$, the standard deviation of the sample mean $\\sigma_{\\bar{x}}$, or **standard error** is:\n",
    "\n",
    "$$ SE = \\frac{\\sigma_{x}}{\\sqrt{n}} $$\n",
    "\n",
    "This allows **to estimate the standard deviation of the sample mean** if we don't perform the simulation process (f.e. because we have no access to the population).\n",
    "\n",
    "Usually, $\\sigma_x$ is not known and is substituted by its empirical estimate (that is sufficiently good if $n>30$ and the population distribution is not skewed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "rows = np.random.choice(df.index.values, 1000)\n",
    "sampled_df = df.loc[rows] \n",
    "\n",
    "sigma_mean = df.std()/math.sqrt(1000)\n",
    "est_sigma_mean = sampled_df.std()/math.sqrt(1000)\n",
    "\n",
    "print('Standard error of the mean using the real SE of the population  :', sigma_mean)\n",
    "print('Standard error using an empirical estimate of the population SE:', est_sigma_mean)\n",
    "print('Estimation of the standard error by simulation (running means)  :', np.array(means).std()) #convert list to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the **standard error of the difference of two sample means** can be constructed from the\n",
    "standard errors of the separate sample means, as follows:\n",
    "\n",
    "$$ SE_{\\bar{x}_1 - \\bar{x}_2 } = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} $$\n",
    "\n",
    "Let's calculate the standard error of the difference between the pregnancy length of first babies and other babies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= len(firstbirth['prglength'])\n",
    "n= len(othersbirth['prglength'])\n",
    "\n",
    "SE = math.sqrt( ((firstbirth['prglength'].std()**2)/(m)) + \\\n",
    "                ((othersbirth['prglength'].std()**2)/(n)) )\n",
    "print(SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real problems we do not have access to the population and the SE is calculated using empirical estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3000 #the higher the N the closest our empirical estimate to the real one \n",
    "rows = np.random.choice(firstbirth.index.values, N)\n",
    "sampled_firstbirth = firstbirth.loc[rows]\n",
    "\n",
    "rowso = np.random.choice(othersbirth.index.values, N)\n",
    "sampled_othersbirth = othersbirth.loc[rowso]\n",
    "\n",
    "SE = math.sqrt( ((sampled_firstbirth['prglength'].std()**2)/(N)) + \\\n",
    "                ((sampled_othersbirth['prglength'].std()**2)/(N)) )\n",
    "print(SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Bootstraping\n",
    "\n",
    "Bootstrapping is a statistical procedure that resamples a single dataset to create many simulated samples. \n",
    "It allows assigning measures of accuracy (defined in terms of bias, variance, etc.) to sample estimates (mean, median, SE, etc). \n",
    "\n",
    "The simplest bootstrap method involves taking an original data set of $N$ values, and sampling from it to form a new sample (called a 'resample' or bootstrap sample) that is also of size $N$. The bootstrap sample is taken from the original using **sampling with replacement** (a population element can be selected more than one time).\n",
    "\n",
    "This process is repeated a large number of times (typically 1,000 or 10,000 times), and for each of these bootstrap samples we compute the desired estimate (each of these are called bootstrap estimates). We now have a histogram of bootstrap estimates. This provides an estimate of the shape of the distribution of the mean from which we can answer questions about how much the mean varies.\n",
    "\n",
    "If the dataset is enormous and computational efficiency is an issue, \n",
    "smaller samples can be used to bootstrap, such as 50% or 80% of the size of the dataset. Check the impact in the following example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "xbar = [0]*10000 #variable to save the means on each bootstrap sample\n",
    "X = np.array(df)\n",
    "elements = 1000  # we take bootstrap samples of 100 elements out of 4413\n",
    "\n",
    "for i in range(10000):\n",
    "    sample = [X[_] for _ in np.random.randint(len(X), size=elements)] # Return 100 integers (indices) bt 0 and 4413\n",
    "    xbar[i] = np.mean(sample)\n",
    "\n",
    "print(np.mean(xbar), np.std(xbar))\n",
    "with plt.style.context('fivethirtyeight'):    \n",
    "    plt.hist(xbar, bins=450, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Let's consider a dataset of accidents in Barcelona in 2019. This dataset can be download from OpenDataBCN website (http://opendata.bcn.cat/), Barcelona's City Hall open data service. Each register in the dataset represents an accident by a series of features: weekday, hour, address, number of dead and injured people, etc. This dataset will represent our population: the set of all reported traffic accidents in Barcelona during 2019.\n",
    "In https://dieguico.cartodb.com/viz/50b06d8c-13ab-11e5-8619-0e4fddd5de28/public_map you can visualize a map of accidents in the city of Barcelona by hour of day, and by day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "#plt.rc('text', usetex=True)\n",
    "#plt.rc('font', family='times')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10) \n",
    "plt.rc('font', size=12) \n",
    "\n",
    "data = pd.read_csv(\"files/2019_accidents_tipus_gu_bcn_.csv\",encoding='latin-1')\n",
    "print(data.columns)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new data column which is the date and a list with the number of accidents for every day of the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column which is the date x : str(x))\n",
    "data['Date'] = '2019-'+data['Mes_any'].apply(lambda x : str(x)) + '-' +  data['Dia_mes'].apply(lambda x : str(x))\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "accidents = data.groupby(['Date']).size()\n",
    "print(\"Mean:\", accidents.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we are interested in describing the number of daily traffic accidents (accident rate) in the streets of Barcelona during 2019. In order to get a first idea of the data, we can plot the number of accidents for each day of 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "plt.ylabel('Number of accidents')\n",
    "plt.xlabel('Day')\n",
    "plt.plot(range(0, 365), np.array(accidents), 'b-+', lw=0.7, alpha=0.7)\n",
    "plt.plot(range(0, 365), [accidents.mean()]*365, 'r-', lw=0.7, alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the distribution of our variable of interest: the daily number of accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Number of accidents')\n",
    "plt.hist(np.array(accidents), bins=20)\n",
    "ax.axvline(x=accidents.mean(), ymin=0, ymax=40, color=[1, 0, 0])\n",
    "plt.savefig(\"bootmean.png\",dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have access to the whole *population*, the computation of the **accident rate** in 2019 is a simple operation: the total number of accidents divided by 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean:\", accidents.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's suppose that we have only access to a limited part of the data\n",
    "(the *sample*): the number of accidents during *some days* of 2019 (let's say 200 days). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = accidents.to_frame()   \n",
    "rows = np.random.choice(df.index.values, 200)\n",
    "sampled_df = df.loc[rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Compute an approximation of the population mean by using a point estimator of the mean and its standard deviation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use the bootstrapping method for estimating the mean and its estandard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Confidence intervals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point estimate provides a *single plausible value for a parameter*. However, a point\n",
    "estimate is rarely perfect; usually there is some error in the estimate. \n",
    "\n",
    "Instead of supplying\n",
    "just a point estimate of a parameter, a next logical step would be to provide *a plausible\n",
    "range of values* for the parameter.\n",
    "\n",
    "A plausible range of values for the population parameter is called a **confidence interval**.\n",
    "\n",
    "Our point estimate is the most plausible value of the parameter, so it makes sense to build\n",
    "the confidence interval around the point estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a point estimate distribution is normal, its standard error SE represents the standard deviation associated with the estimate, and we know that roughly 95% of the time the estimate will be within 1.96 standard errors of the parameter.\n",
    "\n",
    "#### Naive interpretation of the confidence interval\n",
    "\n",
    "If the interval spreads out 1.96 standard errors from a normally distributed point estimate, intuitively we can say that we are **roughly 95% confident that we have captured the true parameter** (*this is not formally true, see later*).\n",
    "\n",
    "$$ CI = [\\mbox{point estimate} - 1.96 \\times SE, \\mbox{point estimate} + 1.96 \\times SE] $$\n",
    "\n",
    "**But what does “95% confident” mean?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "Suppose we took many (infinite) samples and built a confidence\n",
    "interval from each sample. Then about 95% of those intervals\n",
    "would contain the actual parameter.\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = firstbirth['prglength']\n",
    "\n",
    "n = 1000                                              # number of observations\n",
    "N_test = 100                                          # number of samples with n observations\n",
    "means = np.array([0.0] * N_test)                      # samples' mean\n",
    "s = np.array([0.0] * N_test)                          # samples' std\n",
    "ci = np.array([[0.0,0.0]] * N_test)\n",
    "tm = df.mean()                                        # \"true\" mean\n",
    "\n",
    "for i in range(N_test):                               # sample generation and CI computation\n",
    "    rows = np.random.choice(df.index.values, n)\n",
    "    sampled_df = df.loc[rows]\n",
    "    means[i]=sampled_df.mean()\n",
    "    s[i]=sampled_df.std()\n",
    "    ci[i] = means[i] + np.array([-s[i]*1.96/np.sqrt(n), s[i]*1.96/np.sqrt(n)])    \n",
    "\n",
    "out1 = ci[:,0] > tm                                   # CI that do not contain the \"true\" mean\n",
    "out2 = ci[:,1] < tm\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):            # plot of the CI distribution      \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(13, 5))\n",
    "    ind = np.arange(1, N_test+1)\n",
    "    ax.axhline(y=tm, xmin=0, xmax=N_test+1, color=[0, 0, 0])\n",
    "    ci = np.transpose(ci)\n",
    "    ax.plot([ind,ind], ci, color='0.75', marker='_', ms=0, linewidth=3)\n",
    "    ax.plot([ind[out1], ind[out1]], ci[:, out1], color=[1, 0, 0, 0.8], marker='_', ms=0, linewidth=3)\n",
    "    ax.plot([ind[out2], ind[out2]], ci[:, out2], color=[1, 0, 0, 0.8], marker='_', ms=0, linewidth=3)\n",
    "    ax.plot(ind, means, color=[0, .8, .2, .8], marker='.', ms=10, linestyle='')\n",
    "    ax.set_title(\"Confidence interval for the samples' mean estimate of a population\",\n",
    "             fontsize=18)\n",
    "    ax.set_xlabel('Sample (with %d observations). '  %n, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "Our reasoning is based on an important result from probability theory that can be directly applied to our problem: the Central Limit Theorem. **We assume the distribution of our sample is well approximated by a normal model**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to consider confidence intervals where the confidence level is somewhat\n",
    "higher than 95%: perhaps we would like a confidence level of 99% or of 99.9%. In general, if the point estimate follows the normal model with standard error SE, then a\n",
    "confidence interval for the population parameter is \n",
    "\n",
    "$$ \\mbox{point estimate} \\pm z \\times SE_x $$\n",
    "\n",
    "where $z$ corresponds to the confidence level selected:\n",
    "\n",
    "| Confidence Level  | z Value  | \n",
    "|---|---|\n",
    "|  90% | 1.65 |\n",
    "|  95% | 1.96 |\n",
    "|  99% | 2.58 |\n",
    "|  99,9% | 3.291 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting confidence intervals\n",
    "\n",
    "The correct interpretation of a confidence interval is:\n",
    "\n",
    "> In 95% of the cases, when I compute the confidence interval from a sample, the true mean of the population will fall within $\\pm 1.96 \\times SE_x$. 5% of the cases, it will not. \n",
    "\n",
    "Because the true parameter (population mean) is an unknown value, we don’t know if we are in the 5% or the 95%. BUT 95% is pretty good so we say something like “we are 95% confident that we have captured the true parameter\". This is a common shorthand for the idea that the calculations “work” 95% of the time.\n",
    "\n",
    "Remember that we can’t have a 100% confidence interval. By definition, the population mean is not known. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis testing\n",
    "\n",
    "Let's take our initial question: **Were the observed effects related to the birth pregnancy length of first babies real or not?** \n",
    "\n",
    "Technically,  the question is usually translated to: **Were the observed effects statistically significant**? \n",
    "\n",
    "The process of determining the **statistical significance** of an effect is called **hypothesis testing**.\n",
    "\n",
    "This process starts by simplifying the options into two competing hypotheses:\n",
    "\n",
    "+ $H_0$: The mean pregnancy length for first babies and for other babies is the same (there is only one population, one true mean, and ``first babies`` and ``other babies`` are just different samples from the same population).\n",
    "+ $H_A$: The mean pregnancy length for ``first babies`` and for ``other babies`` is different (``first babies`` and ``other babies`` are two samples from two different populations).\n",
    "\n",
    "We call $H_0$ the **null hypothesis** and it represents a *skeptical* point of view: the effect we have observed is due to chance (due to the specific sample bias). \n",
    "\n",
    "$H_A$ is the **alternative hypothesis** and it represents the other point of view: the effect is real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"> <b> Hypothesis Testing </b> <br>\n",
    "The general rule of frequentist hypothesis testing is: we will not <b>accept</b> $H_A$ unless the observed effect is <b>implausible</b> under $H_0$.\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Testing hypotheses using confidence intervals.\n",
    "\n",
    "We can use the concept represented by *confidence intervals* to measure the **plausability** of a hypothesis.\n",
    "\n",
    "We can start the evaluation of the hypotheses setup by comparing first babies and other babies pregnancy length using a *point estimate from the first babies sample*: $ \\bar{x}_{fb} = 38.6$. \n",
    "\n",
    "This estimate suggests the average lenght is actually longer. However, to evaluate\n",
    "whether this provides strong evidence that there is a difference, we must consider the\n",
    "uncertainty associated with $ \\bar{x}_{fb}$ (The difference between\n",
    "$\\bar{x}_{fb}$ and $ \\bar{x}_{ob}$ could be due to sampling variation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our sample, the 95% confidence interval for the mean pregnancy length for first babies can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = firstbirth['prglength']\n",
    "n = len(df)\n",
    "mean=df.mean()\n",
    "s=df.std()\n",
    "ci = [mean - s*1.96/np.sqrt(n),  mean + s*1.96/np.sqrt(n)] \n",
    "print('Mean:', mean, '| CI of the mean:',ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the other babies' mean, 38.52, falls in the range of plausible values, we cannot say the null hypothesis is **implausible**. \n",
    "\n",
    "That is, **we failed to reject the null hypothesis, $H_0$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Interpreting CI tests.\n",
    "\n",
    "Hypothesis testing is built around rejecting or failing to reject the null hypothesis.\n",
    "That is, we do not reject $H_0$ unless we have strong evidence. But what precisely does strong\n",
    "evidence mean? As a general rule of thumb, for those cases where the null hypothesis is\n",
    "actually true, we do not want to incorrectly reject $H_0$ more than 5% of the time. This\n",
    "corresponds to a **significance level** of $\\alpha =0.05$.\n",
    "\n",
    "> If we use a 95% confidence interval to test a hypothesis where the null hypothesis is\n",
    "true, we will make an error whenever the point estimate is at least 1.96 standard errors\n",
    "away from the population parameter. This happens about 5% of the time (2.5% in each\n",
    "tail)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Apply the CI method to the mean rate of traffic accidents in Barcelona during 2018 and 2019 using a point estimate from the 2019 sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimate suggests that during 2019 the mean rate of\n",
    "traffic accidents in Barcelona **was lower** than 2018. But is this effect statistically significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Testing hypotheses using P-values.\n",
    "\n",
    "The modern notion of **statistical significance** was developed by R.A.Fisher in the 1920's when looking for a test to decide whether variation in crop yields were due to some specific intervention or merely random factors beyond experimental control.\n",
    "\n",
    "Fisher first assumed that fertilizer caused no difference (**null hypothesis**) and then calculated $P$ the probability that an observed yield in a fertilized field would occur if fertilizer had no real effect. This probability is called **p-value**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "The <b> P value </b>  is a measure of whether an observed result can be attributed to chance. It is obtained as the\n",
    "the probability of obtaining results at least as extreme as the results actually observed when the null hypothesis of a study question is true.\n",
    "</div>   \n",
    "\n",
    "We typically use a summary statistic of the data, e.g. the sample mean, to help compute the p-value and evaluate the hypotheses. A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis:\n",
    "\n",
    "> Usually, if $P$ is less than 0.05 means there is less than 5% chance your results happened by chance and the the result is declared **statistically significant**. This leads to two possible conclusions: **there is a real effect or the result is an improbable fluke**. Fisher's method offers no way to know which is which."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/p_value.png\" width=\"400\" height=\"100\">\n",
    "\n",
    "**Graphical illustration of a (one-sided) P value**. The curve represents the probability of every observed outcome under the null hypothesis. The P value is the probability of the observed outcome (x) plus all “more extreme” outcomes, represented by the shaded “tail area.” [From Goodman et al., A Dirty Dozen: Twelve P-Value Misconceptions, 2008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of classical hypothesis testing is to answer the question, “*Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?*”\n",
    "\n",
    "Here’s how we answer that question:\n",
    "\n",
    "+ The first step is to quantify the size of the apparent effect by choosing a test statistic. In the NSFG example, the apparent effect is a difference in pregnancy length between first babies and others, so a natural choice for the test statistic is the **difference in means between the two groups**.\n",
    "\n",
    "+ The second step is to define a **null hypothesis**, which is a model of the system based on the assumption that the apparent effect is not real (skeptical point of view). In the NSFG example the null hypothesis is that there is no difference between first babies and others; that is, that pregnancy lengths for both groups have the same distribution.\n",
    "\n",
    "+ The third step is to compute a **p-value**, which is the probability of seeing the apparent effect if the null hypothesis is true. In the NSFG example, we would compute the absolute difference in means, then compute the probability of seeing a difference as big, or bigger, under the null hypothesis.\n",
    "\n",
    "+ The last step is to **interpret the result**. If the p-value is low, the effect is said to be **statistically significant**, which means that it is unlikely to have occurred by chance. In that case we infer that the effect is more likely to appear in the larger population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common error equates **statistical significance** to **practical importance/relevance**. When working with large datasets, we can detect statistical significance for small effects that are meaningless in practical terms. See https://en.wikipedia.org/wiki/Misuse_of_p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Suppose we toss a coin 250 times and see 140 heads and 110 tails. Based on this result, we might suspect that the coin is biased; that is, more likely to land heads. We can compute the p-value of this hypothesis by simulating samples of 250 tossings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "heads, tails = 140,110\n",
    "test = abs(heads - tails)\n",
    "n = heads + tails\n",
    "\n",
    "N = 100000                 # number of samples\n",
    "diff = []                  # list for storing the absolute values of the means' difference\n",
    "\n",
    "for i in range(N):\n",
    "    sample = [random.choice('HT') for _ in range(n)]      # sample generation\n",
    "    h = sample.count('H')                                 # number of H\n",
    "    t = sample.count('T')                                 # number of T\n",
    "    diff.append(abs(h - t))                               # absolute value of the means' differences                         # absolute value of the means' differences\n",
    "\n",
    "count = sum(1 for i in range(N) if diff[i] >= test)       # counting the number of differences\n",
    "                                                          # that are more extreme than the observed \n",
    "                                                          # effect\n",
    "print('P is',float(count)/N)\n",
    "if float(count)/N < 0.05:\n",
    "    print('We cannot discard that the coin is biased.')\n",
    "else:\n",
    "    print('There is no evidence of bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">The most common approach to hypothesis testing is to choose a threshold value for deciding is the effect is likely or not. A common choice is 5% (p-value less than 0.05)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. t-test\n",
    "\n",
    "We saw that the mean pregnancy length for first babies is slighly longer. Let's see if the difference in means is significant.\n",
    "\n",
    "+ The null hypothesis is that the mean of the two groups is the same and the observed difference is due to chance. \n",
    "\n",
    "+ To compute the p-values we can pool the distribution of all live births, generate random samples that are the same size as the observed samples, and compute the difference in means under the null hypothesis.\n",
    "\n",
    "+ If we generate a large number of samples, we can count how often the difference in means (due to chance) is as big or bigger than the difference we actually observed. This fraction is the p-value.\n",
    "\n",
    "This procedure is known as the **t-test** or student's t-test. Note it is a **parametric test**, i.e. it assumes that the data is normally distributed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"> The <b>t-test</b> is a statistical hypothesis test for testing whether two samples are expected to have been drawn from the same population. The test works by checking the means from two samples to see if they are significantly different from each other.  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pregnancy length, we have the following data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= len(firstbirth['prglength'])\n",
    "n= len(othersbirth['prglength'])\n",
    "p = abs(firstbirth['prglength'].mean() - othersbirth['prglength'].mean())\n",
    "print('m:',m, 'n:', n)\n",
    "print('mean difference in weeks: ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To approximate the p-value, we can pool the distributions, generate samples with size $m$ and $n$ and compute the difference in the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = firstbirth['prglength']\n",
    "y = othersbirth['prglength']\n",
    "pool = np.concatenate([x,y])\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):    # plotting the pooled distribution\n",
    "    plt.hist(pool, bins=40, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N = 1000                                            # number of samples\n",
    "diff = []\n",
    "for i in range(N):\n",
    "    p1 = [random.choice(pool) for _ in range(m)]\n",
    "    p2 = [random.choice(pool) for _ in range(n)]\n",
    "    diff.append(abs(np.mean(p1)-np.mean(p2)))\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):          # plotting difference values \n",
    "    plt.hist(diff, bins=50, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2 = np.array(diff)\n",
    "w1 = np.where(diff2 > p)[0]      # counting how many differences are larger than the observed one\n",
    "\n",
    "print('p-value (Simulation)=', len(w1)/float(N), '(', len(w1)/float(N)*100 ,'%)', 'Difference =', p)\n",
    "if len(w1)/float(N)<0.05:\n",
    "    print('The effect is likely')\n",
    "else:\n",
    "    print('The effect is not likely')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common approach to hypothesis testing is to choose a threshold value for deciding is the effect is likely or not. A common choice is 5% (p-value $< 0.05$). \n",
    "\n",
    "So, the effect is not likely!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can calculate the p-value by simulation (as above) or using the python function <code>scipy.stats.ttest_ind</code> https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using python functions\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print('P-value original data (Python function):', \\\n",
    "      ttest_ind(firstbirth['prglength'], othersbirth['prglength'])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Compute the p-value for the SNFG dataset free of outlier values. What is your opinion about this result? Is this effect **relevant**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(preg)\n",
    "df.columns = ['caseid', 'prglength', 'outcome', 'birthord', 'finalwgt']\n",
    "\n",
    "#data cleaning\n",
    "df2 = df.drop(df.index[(df.outcome == 1) & (df['prglength'] > df['prglength'].median() + 6)])\n",
    "df2[(df2.outcome == 1) & (df2['prglength'] > df2['prglength'].median() + 6)]\n",
    "df3 = df2.drop(df2.index[(df2.outcome == 1) & (df2['prglength'] < df2['prglength'].median() - 10)])\n",
    "df3[(df3.outcome == 1) & (df3['prglength'] < df3['prglength'].median() - 10)]\n",
    "\n",
    "firstbirthc = df3[(df3.outcome == 1) & (df3.birthord == 1)]\n",
    "othersbirthc = df3[(df3.outcome == 1) & (df3.birthord >= 2)]\n",
    "\n",
    "m= len(firstbirthc['prglength'])\n",
    "n= len(othersbirthc['prglength'])\n",
    "p = abs(firstbirthc['prglength'].mean() - othersbirthc['prglength'].mean())\n",
    "print('m:',m, 'n:', n)\n",
    "print('mean difference in weeks: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paired or independent samples\n",
    "\n",
    "The t-test can be formulated for independent samples <code>ttest_ind</code> and also for dependent (or paired) samples <code>ttest_rel</code>. \n",
    "\n",
    "What are paired samples? \n",
    "two data sets are \"paired\" when the following one-to-one relationship exists between values in the two data sets:\n",
    "+ Each data set has the same number of data points.\n",
    "+ Each data point in one data set is related to one, and only one, data point in the other data set.\n",
    "\n",
    "Examples of paired samples in ML might be the same algorithm evaluated on different datasets or different algorithms evaluated on exactly the same training and test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold of 5%\n",
    "\n",
    "Note the choice of 5% is arbitrary, and the p-value depends on the choice of the test statistics and the model of the null hypothesis. So p-values should not be considered precise measurements.\n",
    "\n",
    "p-values can be interpreted according to their order of magnitude: if the p-value is less than 1%, the effect is unlikely to be due to chance; if it is greater than 10%, the effect can plausibly be explained by chance. P-values between 1% and 10% should be considered borderline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-sided and two-sided tests.\n",
    "\n",
    "We have defined the effect as *a difference in mean (positive or negative) as big or bigger than $\\delta$*, **ignoring the sign**. A test like this is called **two-sided**. \n",
    "\n",
    "If the relevant question is whether **pregnancy lengths are different for first babies**, then it makes sense to test the absolute difference in means, but if the hypothesis is that **first babies are likely to be late** we would not take the absolute value of the difference. This kind of test is called one-sided because it only counts one side of the distribution of differences. \n",
    "\n",
    "To convert a two-sided test to one-sided text you can multiply the p-value by two and that's it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Chi-squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the t-test to evaluate the significance of the difference in means between first babies and others. \n",
    "BUT when we computed relative risk, we saw that ***first babies are more likely to\n",
    "be early, less likely to be on time, and more likely to be late than other babies***. \n",
    "\n",
    "We can test **hypothesis on ranked (categorical) data** using the **chi-squared test**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">The <b>Chi-Squared test</b> is a non-parametric statistical hypothesis test that assumes (the null hypothesis) that the observed frequencies for a <b>categorical variable</b> match the expected frequencies for the categorical variable. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the chi-squared test by hand we proceed in five easy steps:\n",
    "\n",
    "+ We define a set of categories, called cells, that each sample instance might fall\n",
    "into. Following the babies example, there are six cells because there are two groups\n",
    "(first babies and others) and three bins (early, on time or late).\n",
    "(We can use the following definitions: a baby is early if it is born\n",
    "during Week 37 or earlier, on time if it is born during Week 38, 39 or\n",
    "40, and late if it is born duringWeek 41 or later.)\n",
    "\n",
    "+ We compute the number of babies we expect in each cell. Under the\n",
    "null hypothesis, we assume that the distributions are the same for the\n",
    "two groups, so we can compute the pooled probabilities: $P(early)$,\n",
    "$P(ontime)$ and $P(late)$. For first babies, we have $n$ = 4413 samples, \n",
    "so under the null hypothesis\n",
    "we expect $n \\times P(early)$ first babies to be early, $n \\times  P(ontime)$ to be\n",
    "on time, etc. Likewise, we have $m$ = 4735 other babies, so we expect\n",
    "$m \\times  P(early)$ other babies to be early, etc.\n",
    "\n",
    "+ For each cell we compute the deviation; that is, the difference between the observed value, \n",
    "$O_i$, and the expected value, $E_i$.\n",
    "\n",
    "+ We compute some measure of the **total deviation**; this quantity is called the test statistic. The most common choice here is the **chi-square statistic**:\n",
    "\n",
    "$$ \\chi^2 = \\sum_i \\frac{(O_i - E_i)^2}{E_i} $$\n",
    "\n",
    "+ We can use simulation to compute the p-value, which is\n",
    "the probability of seeing a chi-square statistic as high as the observed\n",
    "value under the null hypothesis.\n",
    "\n",
    "When the chi-square statistic is used, this process is called a **chi-square test**.\n",
    "One feature of the chi-square test is that the distribution of the test statistic\n",
    "can be computed analytically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chi-square test and the p-value of the test can be obtained with the python function <code>scipy.stats.chisquare</code> https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "a = chisquare([16, 18, 16, 14, 12, 12], [16, 16, 16, 16, 16, 16])\n",
    "print('Chi-squared test statistic:', a[0], 'P-value of the test', a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Using the data from the NSFG, compute the Chi-squared test statistic and its p-value. Use clean data (no outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Wilcoxon Signed-Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wilcoxon signed rank test uses the sum of the signed ranks as the test statistic $𝑊$:\n",
    "$$W=\\sum_{i=1}^{N}[\\text{sgn}(x_{2,i}-x_{1,i})*R_i]$$\n",
    "where the i-th of N measurement pairs is indicated by ($x_{1,i},x_{2,i}$) and $R_i$ denotes the rank of the pair. The rank simply represents the position of an observation in an ordered list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">The <b>Wilcoxon signed-rank test</b> is a nonparametric statistical hypothesis test that compares two paired samples to assess whether their population mean ranks differ.</div>\n",
    "\n",
    "\n",
    "The Wilcoxon signed-rank test and the p-value of the test can be obtained with the python optimization  <code>scipy.stats.wilcoxon</code> https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html \n",
    "\n",
    "Note that, by default (only one input), it is applied to differences between two sets of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "data1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "data2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\n",
    "stat, p = wilcoxon(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> In machine learning, non-parametric statistical tests are often used on samples of model skill scores in order to confirm that the difference in skill between models is significant</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist general inference: Conclusions.\n",
    "\n",
    "+ Point estimates are useful to build hypotheses.\n",
    "+ We can measure the variability of the predicted estimate (PE) with standard error (SE) or 95% confidence intervals.\n",
    "+ We measure the statistical significant of our hypothesis $H_A$ by formulating the null hipothesis ($H_0$) and computing $P(E|H_0)$ (setting a threshold $\\alpha$ in advance, which is usually 0.05):\n",
    "    + Accept $H_A$ if $P(E|H_0) < \\alpha$.\n",
    "    + Accept $H_0$ if $P(E|H_0) \\geq \\alpha$.\n",
    "+ Non-parametric statistical hypothesis tests quantify the likelihood that two data samples have the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The skeptic view\n",
    "\n",
    "No matter how much data you have, you will still depend on intuition to decide how to interpret, explain and use the data.\n",
    "\n",
    "Data can’t say anything. Data scientists are interpreters, offering one interpretation of what the useful narrative story derived from the data is (if there is one at all).\n",
    "\n",
    "Cognitive Bias (f.e. confirmation bias, narrative bias) pollutes our view of data. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
